{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helo From Notebook\n"
     ]
    }
   ],
   "source": [
    "print(\"Helo From Notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import os\n",
    "import numpy as np \n",
    "import cv2 # type: ignore\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input # type: ignore\n",
    "from tensorflow.keras.preprocessing import image # type: ignore\n",
    "import camogen # Replace with the actual camouflage generator library\n",
    "from sklearn.cluster import KMeans # type: ignore\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images loaded: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def read_images_from_folder(folder_path='./input_images'):\n",
    "    \"\"\"\n",
    "    Read all images from a specified folder and return them as a list of numpy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder containing images (default is './input_images').\n",
    "    \n",
    "    Returns:\n",
    "    - image_list (list of numpy arrays): List of images as numpy arrays.\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')  # Valid image file extensions\n",
    "    \n",
    "    # Loop through all the files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(valid_extensions):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(file_path)\n",
    "            \n",
    "            if img is not None:  # Ensure the image was successfully read\n",
    "                image_list.append(img)\n",
    "    \n",
    "    return image_list\n",
    "\n",
    "# Example usage\n",
    "image_list = read_images_from_folder('./input_images')\n",
    "print(f\"Total images loaded: {len(image_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract dominant colors from multiple images using K-means clustering\n",
    "def extract_colors_kmeans(image_list, num_colors=3):\n",
    "    \"\"\"\n",
    "    Use K-means clustering to extract dominant colors from multiple images.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_list (list of numpy arrays): List of images as numpy arrays.\n",
    "    - num_colors (int): Number of dominant colors to extract.\n",
    "    \n",
    "    Returns:\n",
    "    - list of hex color strings.\n",
    "    \"\"\"\n",
    "    all_pixels = []\n",
    "\n",
    "    for img in image_list:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.reshape((img.shape[0] * img.shape[1], 3))  # Flatten image into list of pixels\n",
    "        all_pixels.extend(img)\n",
    "\n",
    "    all_pixels = np.array(all_pixels)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(all_pixels)\n",
    "    colors = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "    # Convert to HEX color format\n",
    "    return [f\"#{b:02x}{g:02x}{r:02x}\" for r, g, b in colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract deep features using a pre-trained CNN (VGG16)\n",
    "def extract_deep_features(image_list):\n",
    "    \"\"\"\n",
    "    Extract deep features from multiple images using a pretrained VGG16 model.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_list (list of numpy arrays): List of images as numpy arrays.\n",
    "    \n",
    "    Returns:\n",
    "    - Aggregated deep features (numpy array).\n",
    "    \"\"\"\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    all_features = []\n",
    "\n",
    "    for img in image_list:\n",
    "        img = cv2.resize(img, (224, 224))  # Resize to the input size for VGG16\n",
    "        img_data = np.expand_dims(img, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        \n",
    "        features = model.predict(img_data)\n",
    "        all_features.append(features.flatten())\n",
    "    \n",
    "    # Average the features across all images\n",
    "    return np.mean(all_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "0.66399825 6.9017377\n",
      "{'width': 500, 'height': 500, 'polygon_size': 12, 'color_bleed': 3, 'colors': ['#3b4a54', '#18222a', '#62757d', '#99a9ae'], 'max_depth': 44, 'spots': {'amount': 65, 'radius': {'min': 23, 'max': 33}, 'sampling_variation': 34}, 'pixelize': {'percentage': 0.44508688449859624, 'sampling_variation': 34, 'density': {'x': 116, 'y': 116}}}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Use deep features to dynamically set spots, pixel, and other parameters\n",
    "def determine_dynamic_params(deep_features, base_spot_amount=10, base_pixel_amount=0.1):\n",
    "    \"\"\"\n",
    "    Dynamically adjust the spots, pixelization, polygon size, color bleed, and max depth\n",
    "    parameters based on extracted deep features.\n",
    "    \n",
    "    Parameters:\n",
    "    - deep_features (numpy array): Extracted deep features from the environment images.\n",
    "    - base_spot_amount (int): Base number of spots.\n",
    "    - base_pixel_amount (float): Base amount of pixelization.\n",
    "    \n",
    "    Returns:\n",
    "    - spots_params (dict): Parameters for spots.\n",
    "    - pixelize_params (dict): Parameters for pixelization.\n",
    "    - polygon_size (int): Dynamically determined polygon size.\n",
    "    - color_bleed (int): Dynamically determined color bleed.\n",
    "    - max_depth (int): Dynamically determined max depth.\n",
    "    \"\"\"\n",
    "    feature_variance = np.var(deep_features)  # Use variance as a measure of complexity\n",
    "    feature_mean = np.mean(deep_features)    # Use mean to determine general texture complexity\n",
    "    \n",
    "    print(feature_mean,feature_variance)\n",
    "\n",
    "    # Adjust spots based on texture complexity (high variance -> more spots)\n",
    "    spot_amount = int(base_spot_amount + feature_variance * 8)\n",
    "    spot_radius_min = max(5, 10 + int(feature_mean * 20))  # Minimum spot size related to mean feature\n",
    "    spot_radius_max = spot_radius_min + 10  # Max radius is a bit larger than min\n",
    "    \n",
    "    spots_params = {\n",
    "        \"amount\": spot_amount,\n",
    "        \"radius\": {'min': spot_radius_min, 'max': spot_radius_max},\n",
    "        \"sampling_variation\": int(feature_variance * 5)  # Adjust variation based on feature variance\n",
    "    }\n",
    "    \n",
    "    # Adjust pixelization based on complexity (more complex textures -> more pixelization)\n",
    "    pixelize_amount = min(0.5, base_pixel_amount + feature_variance / 10)\n",
    "    pixel_density_x = 50 + int(feature_mean * 100)  # Increase pixel density based on feature mean\n",
    "    pixel_density_y = pixel_density_x\n",
    "    \n",
    "    pixelize_params = {\n",
    "        \"percentage\": pixelize_amount,\n",
    "        \"sampling_variation\": int(feature_variance * 5),\n",
    "        \"density\": {'x': pixel_density_x, 'y': pixel_density_y}\n",
    "    }\n",
    "    \n",
    "    # Dynamically set polygon size (smaller for higher variance)\n",
    "    polygon_size = int(100 / (feature_variance + 1))  # Larger variance -> smaller polygons\n",
    "    \n",
    "    # Dynamically set color bleed (smoother textures -> higher bleed)\n",
    "    color_bleed = int(10 * (1 - feature_mean))  # Lower mean -> more bleed\n",
    "\n",
    "    # Dynamically set max depth (higher for more complex textures)\n",
    "    max_depth = int(10 + feature_variance * 5)\n",
    "\n",
    "    return spots_params, pixelize_params, polygon_size, color_bleed, max_depth\n",
    "\n",
    "\n",
    "def generate_camouflage(image_list,num_colors):\n",
    "    \n",
    "    environment_colors = extract_colors_kmeans(image_list, num_colors=num_colors)\n",
    "    deep_features = extract_deep_features(image_list)\n",
    "    \n",
    "    # Determine dynamic parameters (spots, pixelization, polygon size, color bleed, max depth)\n",
    "    spots_params, pixelize_params, polygon_size, color_bleed, max_depth = determine_dynamic_params(deep_features)\n",
    "    \n",
    "    # Define base camouflage parameters\n",
    "    camouflage_params = {\n",
    "        \"width\": 1500,\n",
    "        \"height\": 1500,\n",
    "        \"polygon_size\": polygon_size,\n",
    "        \"color_bleed\": color_bleed,\n",
    "        \"colors\": environment_colors,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"spots\": spots_params,\n",
    "        \"pixelize\": pixelize_params\n",
    "        \n",
    "    }\n",
    "\n",
    "    print(camouflage_params)\n",
    "    # Generate the camouflage using the camouflage generator library\n",
    "    # Generate the camouflage using the camouflage generator library\n",
    "    camouflage_image = camogen.generate(camouflage_params)\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # # Save the image to a BytesIO stream\n",
    "    #     img_io = io.BytesIO()\n",
    "    #     camouflage_image.save(img_io, 'PNG')\n",
    "    #     img_io.seek(0)\n",
    "\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    output_file_path = f'./static/images/patterns/camouflaged_{timestamp}.png'\n",
    "\n",
    "    camouflage_image.save(\"./static/images/patterns/output_file_path.png\")\n",
    "\n",
    "    # IMAGE_FOLDER = os.path.join('static','images', 'patterns')\n",
    "\n",
    "     # Output path for the camouflaged image (it will be saved in the /images/pattern folder)\n",
    "    # final_output_path = os.path.join(IMAGE_FOLDER, output_file_path)\n",
    "\n",
    "    path_img = f'images/patterns/camouflaged_{timestamp}.png'\n",
    "\n",
    "    return path_img\n",
    "\n",
    "image_path  = generate_camouflage(image_list=image_list,num_colors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
